{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Airbnb Capstone Project"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### import all libraries and set settings \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import requests\n",
    "\n",
    "from py_functions import increase_bbox\n",
    "from py_functions import get_dataframe\n",
    "from py_functions import get_engine\n",
    "from sklearn.neighbors import BallTree\n",
    "from scipy.spatial import cKDTree\n",
    "from shapely.geometry import Point\n",
    "from shapely.ops import transform\n",
    "from functools import partial\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import threading\n",
    "from threading import Thread\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor, process, wait\n",
    "\n",
    "pd.set_option('display.max_columns', None) # show all columns  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download osm_short from postgresql database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = get_engine()\n",
    "schema = 'hh_analytics_23_1' # your course schema name, example 'hh_analytics_22_1\n",
    "table_name = 'g1_osm_short'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "osm_short = get_dataframe(f'SELECT * FROM {schema}.{table_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>name</th>\n",
       "      <th>amenity</th>\n",
       "      <th>cuisine</th>\n",
       "      <th>diet_vegetarian</th>\n",
       "      <th>diet_vegan</th>\n",
       "      <th>railway</th>\n",
       "      <th>address</th>\n",
       "      <th>gastronomy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>451152</td>\n",
       "      <td>51.600840</td>\n",
       "      <td>-0.194608</td>\n",
       "      <td>King of Prussia</td>\n",
       "      <td>bar</td>\n",
       "      <td>pizza;burger</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>363 Regents Park Road London N3 1DH</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>451153</td>\n",
       "      <td>51.602031</td>\n",
       "      <td>-0.193503</td>\n",
       "      <td>Central Restaurant</td>\n",
       "      <td>restaurant</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id   latitude  longitude                name     amenity       cuisine  \\\n",
       "0  451152  51.600840  -0.194608     King of Prussia         bar  pizza;burger   \n",
       "1  451153  51.602031  -0.193503  Central Restaurant  restaurant          None   \n",
       "\n",
       "  diet_vegetarian diet_vegan railway                              address  \\\n",
       "0            True       True    None  363 Regents Park Road London N3 1DH   \n",
       "1            None       None    None                                 None   \n",
       "\n",
       "   gastronomy  \n",
       "0       False  \n",
       "1        True  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "osm_short.head(2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Restaurant scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New DF for bars with addresses and names to fill with reviews\n",
    "bar_address = osm_short[(osm_short[\"amenity\"] == \"bar\") & (~osm_short[\"address\"].isna()) & (~osm_short[\"name\"].isna())]\n",
    "bar_address = bar_address.reset_index().drop(columns=\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment both only the first time this is run.\n",
    "# bar_reviews = pd.DataFrame(columns=[\"id\",\"name\",\"rating\",\"reviews\",\"price\",\"closed\",\"url\"])\n",
    "# bar_reviews.to_csv(\"data/london/bar_address.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 The Rose 4.2\n",
      "0 The Rose 1,389\n",
      "0 The Rose False\n",
      "0 The Rose €€\n",
      "{'id': 1168160316, 'name': 'The Rose', 'rating': '4.2', 'reviews': '1,389', 'price': '€€', 'closed': 'False', 'url': 'http://maps.google.com/?q=The Rose+35 Albert Embankment  SE1 7TL'}\n"
     ]
    }
   ],
   "source": [
    "# THIS ONE, \"bar_address\" must be csv on computer\n",
    "# bars, address not nan, web scraping loop with threading\n",
    "\n",
    "bar_reviews = pd.read_csv(\"data/london/bar_reviews.csv\", index_col=\"Unnamed: 0\")\n",
    "bar_address_remaining = bar_address[~bar_address[\"id\"].isin(bar_reviews[\"id\"].to_list())]\n",
    "\n",
    "\n",
    "service = Service(ChromeDriverManager().install())\n",
    "\n",
    "def driver_setup():\n",
    "    options = Options()\n",
    "    options.add_argument(\"--headless=new\")\n",
    "    options.add_argument('--no-sandbox')\n",
    "    options.add_argument('--disable-dev-shm-usage')\n",
    "    driver = webdriver.Chrome(service=service, options=options)\n",
    "    return driver\n",
    "\n",
    "def get_rating(i):\n",
    "    global bar_reviews\n",
    "    bar_id = bar_address_remaining[\"id\"].iloc[i]\n",
    "    bar_name = bar_address_remaining[\"name\"].iloc[i]\n",
    "    driver=driver_setup()\n",
    "    url = f'http://maps.google.com/?q={bar_address_remaining[\"name\"].iloc[i]}+{bar_address_remaining[\"address\"].iloc[i]}'\n",
    "    driver.get(url)\n",
    "    time.sleep(1)\n",
    "\n",
    "\n",
    "    # Press accept all on cookie question\n",
    "    try:\n",
    "        driver.find_element(By.XPATH,'//*[@id=\"yDmH0d\"]/c-wiz/div/div/div/div[2]/div[1]/div[3]/div[1]/div[1]/form[2]/div/div/button/span').click()\n",
    "        time.sleep(1)\n",
    "    except NoSuchElementException:\n",
    "        pass\n",
    "    \n",
    "    # Extract raiting/num of reviews, price level and if permanently closed\n",
    "    try:\n",
    "        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "        case_reviews = soup.find('div', class_ = 'F7nice')\n",
    "        case_rating = case_reviews.text.split(\"(\")[0]\n",
    "        case_reviews = case_reviews.text.split(\"(\")[1][:-1]\n",
    "        print(i, bar_address_remaining[\"name\"].iloc[i], case_rating)\n",
    "        print(i, bar_address_remaining[\"name\"].iloc[i], case_reviews)\n",
    "    except Exception:\n",
    "        case_rating = np.nan\n",
    "        case_reviews = np.nan\n",
    "        print(i, bar_address_remaining[\"name\"].iloc[i], \"Rating no\")\n",
    "        pass\n",
    "   \n",
    "    try:\n",
    "        case_closed = str(\"Temporarily closed\" in soup.find('div', class_ = 'skqShb').text)\n",
    "        print(i, bar_address_remaining[\"name\"].iloc[i], case_closed)\n",
    "    except Exception:\n",
    "        case_closed = np.nan\n",
    "        print(i, bar_address_remaining[\"name\"].iloc[i], \"Closed no\")\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        case_price = soup.find('span', class_ = 'mgr77e').text[1:]\n",
    "        print(i, bar_address_remaining[\"name\"].iloc[i], case_price)\n",
    "    except Exception:\n",
    "        case_price = np.nan\n",
    "        print(i, bar_address_remaining[\"name\"].iloc[i], \"Euro no\")\n",
    "        pass\n",
    "   \n",
    "        \n",
    "\n",
    "    poi_url = url\n",
    "    row = {\"id\": bar_id, \"name\": bar_name, \"rating\": case_rating, \"reviews\": case_reviews, \"price\": case_price, \"closed\": case_closed, \"url\": poi_url}\n",
    "    print(row)\n",
    "    bar_reviews = pd.concat([bar_reviews, pd.DataFrame(row, index=[i])], ignore_index=True)\n",
    "\n",
    "    driver.close()\n",
    "    return bar_reviews\n",
    "\n",
    "# Insert number of iterations in range\n",
    "threadlist = []\n",
    "with ThreadPoolExecutor(max_workers=4) as executor:\n",
    "    for i in range(1):\n",
    "        threadlist.append(executor.submit(get_rating, i))\n",
    "        time.sleep(1)\n",
    "\n",
    "wait(threadlist)\n",
    "\n",
    "bar_reviews = bar_reviews.drop_duplicates(subset=\"id\", keep=False)\n",
    "bar_reviews.to_csv('data/london/bar_reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>rating</th>\n",
       "      <th>reviews</th>\n",
       "      <th>price</th>\n",
       "      <th>closed</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3508</th>\n",
       "      <td>316763495</td>\n",
       "      <td>Dirty Martini St. Pauls</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1,091</td>\n",
       "      <td>€€</td>\n",
       "      <td>False</td>\n",
       "      <td>http://maps.google.com/?q=Dirty Martini St. Pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3509</th>\n",
       "      <td>10862052885</td>\n",
       "      <td>The Black Horse</td>\n",
       "      <td>4.6</td>\n",
       "      <td>37</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>http://maps.google.com/?q=The Black Horse+1 Wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3510</th>\n",
       "      <td>146986838</td>\n",
       "      <td>The Long Lane</td>\n",
       "      <td>5.0</td>\n",
       "      <td>77</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>http://maps.google.com/?q=The Long Lane+52 Lon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3511</th>\n",
       "      <td>439335533</td>\n",
       "      <td>Lamb and Trotter</td>\n",
       "      <td>4.4</td>\n",
       "      <td>187</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>http://maps.google.com/?q=Lamb and Trotter+6 L...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3512</th>\n",
       "      <td>1168160316</td>\n",
       "      <td>The Rose</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1,389</td>\n",
       "      <td>€€</td>\n",
       "      <td>False</td>\n",
       "      <td>http://maps.google.com/?q=The Rose+35 Albert E...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               id                     name rating reviews price closed  \\\n",
       "3508    316763495  Dirty Martini St. Pauls    3.7   1,091    €€  False   \n",
       "3509  10862052885          The Black Horse    4.6      37   NaN  False   \n",
       "3510    146986838            The Long Lane    5.0      77   NaN  False   \n",
       "3511    439335533         Lamb and Trotter    4.4     187   NaN  False   \n",
       "3512   1168160316                 The Rose    4.2   1,389    €€  False   \n",
       "\n",
       "                                                    url  \n",
       "3508  http://maps.google.com/?q=Dirty Martini St. Pa...  \n",
       "3509  http://maps.google.com/?q=The Black Horse+1 Wi...  \n",
       "3510  http://maps.google.com/?q=The Long Lane+52 Lon...  \n",
       "3511  http://maps.google.com/?q=Lamb and Trotter+6 L...  \n",
       "3512  http://maps.google.com/?q=The Rose+35 Albert E...  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bar_reviews.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload review data for bars that had addresses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>rating</th>\n",
       "      <th>reviews</th>\n",
       "      <th>price</th>\n",
       "      <th>closed</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>451152</td>\n",
       "      <td>King of Prussia</td>\n",
       "      <td>4.5</td>\n",
       "      <td>291</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>http://maps.google.com/?q=King of Prussia+363 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>451154</td>\n",
       "      <td>The Catcher in the Rye</td>\n",
       "      <td>4.2</td>\n",
       "      <td>811</td>\n",
       "      <td>€€</td>\n",
       "      <td>False</td>\n",
       "      <td>http://maps.google.com/?q=The Catcher in the R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>451271</td>\n",
       "      <td>The Tally Ho</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1,330</td>\n",
       "      <td>€</td>\n",
       "      <td>False</td>\n",
       "      <td>http://maps.google.com/?q=The Tally Ho+749 Hig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12243302</td>\n",
       "      <td>The George</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1,678</td>\n",
       "      <td>€</td>\n",
       "      <td>False</td>\n",
       "      <td>http://maps.google.com/?q=The George+ High Str...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15262028</td>\n",
       "      <td>The Monkey Puzzle</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1,502</td>\n",
       "      <td>€€</td>\n",
       "      <td>False</td>\n",
       "      <td>http://maps.google.com/?q=The Monkey Puzzle+30...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3502</th>\n",
       "      <td>1155385349</td>\n",
       "      <td>The Old White Lion</td>\n",
       "      <td>4.3</td>\n",
       "      <td>1,153</td>\n",
       "      <td>€€</td>\n",
       "      <td>False</td>\n",
       "      <td>http://maps.google.com/?q=The Old White Lion+1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3503</th>\n",
       "      <td>987866346</td>\n",
       "      <td>The Havelock Tavern</td>\n",
       "      <td>4.4</td>\n",
       "      <td>532</td>\n",
       "      <td>€€</td>\n",
       "      <td>False</td>\n",
       "      <td>http://maps.google.com/?q=The Havelock Tavern+...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3504</th>\n",
       "      <td>1164893696</td>\n",
       "      <td>The Triple Crown</td>\n",
       "      <td>3.9</td>\n",
       "      <td>53</td>\n",
       "      <td>€</td>\n",
       "      <td>False</td>\n",
       "      <td>http://maps.google.com/?q=The Triple Crown+15 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3505</th>\n",
       "      <td>1162262556</td>\n",
       "      <td>The Volunteer</td>\n",
       "      <td>4.4</td>\n",
       "      <td>198</td>\n",
       "      <td>€€</td>\n",
       "      <td>False</td>\n",
       "      <td>http://maps.google.com/?q=The Volunteer+46 Chu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3506</th>\n",
       "      <td>1164917391</td>\n",
       "      <td>The Windmill</td>\n",
       "      <td>4.3</td>\n",
       "      <td>372</td>\n",
       "      <td>€€</td>\n",
       "      <td>False</td>\n",
       "      <td>http://maps.google.com/?q=The Windmill+44 Lamb...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3108 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id                    name rating reviews price closed  \\\n",
       "0         451152         King of Prussia    4.5     291   NaN  False   \n",
       "1         451154  The Catcher in the Rye    4.2     811    €€  False   \n",
       "2         451271            The Tally Ho    4.0   1,330     €  False   \n",
       "3       12243302              The George    4.1   1,678     €  False   \n",
       "4       15262028       The Monkey Puzzle    4.5   1,502    €€  False   \n",
       "...          ...                     ...    ...     ...   ...    ...   \n",
       "3502  1155385349      The Old White Lion    4.3   1,153    €€  False   \n",
       "3503   987866346     The Havelock Tavern    4.4     532    €€  False   \n",
       "3504  1164893696        The Triple Crown    3.9      53     €  False   \n",
       "3505  1162262556           The Volunteer    4.4     198    €€  False   \n",
       "3506  1164917391            The Windmill    4.3     372    €€  False   \n",
       "\n",
       "                                                    url  \n",
       "0     http://maps.google.com/?q=King of Prussia+363 ...  \n",
       "1     http://maps.google.com/?q=The Catcher in the R...  \n",
       "2     http://maps.google.com/?q=The Tally Ho+749 Hig...  \n",
       "3     http://maps.google.com/?q=The George+ High Str...  \n",
       "4     http://maps.google.com/?q=The Monkey Puzzle+30...  \n",
       "...                                                 ...  \n",
       "3502  http://maps.google.com/?q=The Old White Lion+1...  \n",
       "3503  http://maps.google.com/?q=The Havelock Tavern+...  \n",
       "3504  http://maps.google.com/?q=The Triple Crown+15 ...  \n",
       "3505  http://maps.google.com/?q=The Volunteer+46 Chu...  \n",
       "3506  http://maps.google.com/?q=The Windmill+44 Lamb...  \n",
       "\n",
       "[3108 rows x 7 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# closed is only NaN if the place was not found in the google search, otherwise it would be True or False\n",
    "bar_reviews = bar_reviews[(~bar_reviews[\"closed\"].isna())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from py_functions import get_engine\n",
    "import psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = get_engine()\n",
    "schema = 'hh_analytics_23_1' # your course schema name, example 'hh_analytics_22_1\n",
    "table_name = 'g1_bar_reviews'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The g1_bar_reviews table was imported successfully.\n"
     ]
    }
   ],
   "source": [
    "# Write records stored in poi_gastro to SQL database\n",
    "if engine!=None:\n",
    "    try:\n",
    "        bar_reviews.to_sql(name=table_name, # Name of SQL table variable\n",
    "                        con=engine, # Engine or connection\n",
    "                        schema=schema, # your class schema variable\n",
    "                        if_exists='fail', # Drop the table before inserting new values \n",
    "                        index=False, # Write DataFrame index as a column\n",
    "                        chunksize=5000, # Specify the number of rows in each batch to be written at a time\n",
    "                        method='multi') # Pass multiple values in a single INSERT clause\n",
    "        print(f\"The {table_name} table was imported successfully.\")\n",
    "    # Error handling\n",
    "    except (Exception, psycopg2.DatabaseError) as error:\n",
    "        print(error)\n",
    "        engine = None\n",
    "else:\n",
    "    print('No engine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Give access to all cohort members\n",
    "group = \"student_role_hh_analytics_23_1\"\n",
    "engine = get_engine()\n",
    "SQL = f\"GRANT ALL  ON {schema}.{table_name} to {group}\"\n",
    "with engine.begin() as conn:\n",
    "    conn.execute(SQL)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scraping for bars without or without correct address by lat/long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bar_no_address = osm_short[(osm_short[\"amenity\"] == \"bar\") & (osm_short[\"address\"].isna()) & (~osm_short[\"name\"].isna())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No working address\n",
    "bar_remaining = bar_reviews[(bar_reviews[\"closed\"].isna())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bar_no_address = pd.concat([bar_no_address, bar_remaining])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bar_no_address = bar_no_address.reset_index().drop(columns=\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment both only the first time\n",
    "# bar_reviews_no_add = bar_reviews[0:0]\n",
    "# bar_reviews_no_add.to_csv(\"data/london/bar_reviews_no_add.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose from list, \"bar_reviews_no_address\" must be csv on computer\n",
    "# bars, address not nan, web scraping loop with threading\n",
    "pd.options.mode.chained_assignment = \"warn\"\n",
    "\n",
    "bar_reviews_no_add = pd.read_csv(\"data/london/bar_reviews_no_add.csv\", index_col=\"Unnamed: 0\")\n",
    "bar_no_add_remaining = bar_no_address[~bar_no_address[\"id\"].isin(bar_reviews_no_add[\"id\"].to_list())]\n",
    "\n",
    "\n",
    "service = Service(ChromeDriverManager().install())\n",
    "\n",
    "def driver_setup():\n",
    "    options = Options()\n",
    "    options.add_argument(\"--headless=new\")\n",
    "    options.add_argument('--no-sandbox')\n",
    "    options.add_argument('--disable-dev-shm-usage')\n",
    "    driver = webdriver.Chrome(service=service, options=options)\n",
    "    return driver\n",
    "\n",
    "def get_rating(i):\n",
    "    global bar_reviews_no_add\n",
    "    bar_id = bar_no_add_remaining[\"id\"].iloc[i]\n",
    "    bar_name = bar_no_add_remaining[\"name\"].iloc[i]\n",
    "    driver=driver_setup()\n",
    "    url = f'http://maps.google.com/?ll={bar_no_add_remaining[\"latitude\"].iloc[i]},{bar_no_add_remaining[\"longitude\"].iloc[i]}'\n",
    "    driver.get(url)\n",
    "    time.sleep(1)\n",
    "\n",
    "\n",
    "    # Press accept all on cookie question\n",
    "    try:\n",
    "        driver.find_element(By.XPATH,'//*[@id=\"yDmH0d\"]/c-wiz/div/div/div/div[2]/div[1]/div[3]/div[1]/div[1]/form[2]/div/div/button/span').click()\n",
    "        time.sleep(1)\n",
    "    except NoSuchElementException:\n",
    "        pass\n",
    "\n",
    "    driver.get(url)\n",
    "\n",
    "    driver.find_element(By.XPATH,'/html/body/div[3]/div[9]/div[3]/div[1]/div[1]/div[1]/div[2]/form/div[2]/div[3]/div/input[1]').send_keys(bar_no_add_remaining[\"name\"].iloc[i])\n",
    "    driver.find_element(By.XPATH,'/html/body/div[3]/div[9]/div[3]/div[1]/div[1]/div[1]/div[2]/form/div[2]/div[3]/div/input[1]').send_keys(Keys.RETURN)\n",
    "    time.sleep(4)\n",
    "\n",
    "\n",
    "\n",
    "    # Extract raiting/num of reviews, price level and if permanently closed\n",
    "    try:\n",
    "        # Case for immediate result without list appearing\n",
    "        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "        case_reviews = soup.find('div', class_ = 'F7nice')\n",
    "        case_rating = case_reviews.text.split(\"(\")[0]\n",
    "        case_reviews = case_reviews.text.split(\"(\")[1][:-1]\n",
    "        #print(i, bar_no_add_remaining[\"name\"].iloc[i], case_rating)\n",
    "        #print(i, bar_no_add_remaining[\"name\"].iloc[i], case_reviews)\n",
    "    except Exception:\n",
    "        try:\n",
    "            try:\n",
    "                # Count the number of ads and skip them\n",
    "                ads = soup.find_all('span', {'class': 'jHLihd'})\n",
    "                #print(ads)\n",
    "                len_ads = len(ads)\n",
    "                ads_first = ads[0]\n",
    "                #print(bar_no_add_remaining[\"name\"].iloc[i], \"len ads\", len(ads))\n",
    "                #print(bar_no_add_remaining[\"name\"].iloc[i], \"ads 1\", ads[0])\n",
    "                if len(ads) > 0:\n",
    "                    try:\n",
    "                        #print(bar_no_add_remaining[\"name\"].iloc[i], \"len ads over 0\")\n",
    "                        click_list = driver.find_elements(By.CLASS_NAME, 'hfpxzc')\n",
    "                        #print(bar_no_add_remaining[\"name\"].iloc[i], click_list[len(ads)])\n",
    "                        click_list[len(ads)].click()\n",
    "                        time.sleep(2)\n",
    "                        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "                        case_reviews = soup.find('div', class_ = 'F7nice')\n",
    "                        case_rating = case_reviews.text.split(\"(\")[0]\n",
    "                        case_reviews = case_reviews.text.split(\"(\")[1][:-1]\n",
    "                    except Exception:\n",
    "                        pass\n",
    "            except Exception:\n",
    "                # Case if no ads\n",
    "                #print(bar_no_add_remaining[\"name\"].iloc[i], \"no ads\")\n",
    "                driver.find_element(By.CLASS_NAME, 'hfpxzc').click()\n",
    "                time.sleep(2)\n",
    "                soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "                case_reviews = soup.find('div', class_ = 'F7nice')\n",
    "                case_rating = case_reviews.text.split(\"(\")[0]\n",
    "                case_reviews = case_reviews.text.split(\"(\")[1][:-1]\n",
    "                #print(\"try list hit\")\n",
    "                #print(i, bar_no_add_remaining[\"name\"].iloc[i], case_rating)\n",
    "                #print(i, bar_no_add_remaining[\"name\"].iloc[i], case_reviews)\n",
    "                pass\n",
    "        except Exception:\n",
    "            try:\n",
    "                # If neither direct hit nor list, try again (moves to exception and sets nan)\n",
    "                soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "                case_reviews = soup.find('div', class_ = 'F7nice')\n",
    "                case_rating = case_reviews.text.split(\"(\")[0]\n",
    "                case_reviews = case_reviews.text.split(\"(\")[1][:-1]\n",
    "                #print(\"try no hit\")\n",
    "                #print(i, bar_no_add_remaining[\"name\"].iloc[i], case_rating)\n",
    "                #print(i, bar_no_add_remaining[\"name\"].iloc[i], case_reviews)\n",
    "            except Exception:\n",
    "                case_rating = np.nan\n",
    "                case_reviews = np.nan\n",
    "                #print(\"try no hit no rev/rating\")\n",
    "                #print(i, bar_no_add_remaining[\"name\"].iloc[i], case_rating)\n",
    "                #print(i, bar_no_add_remaining[\"name\"].iloc[i], case_reviews)\n",
    "                pass\n",
    "        pass\n",
    "    try:\n",
    "        if str(\"Temporarily closed\" in soup.find('div', class_ = 'skqShb').text):\n",
    "            case_closed = str(\"Temporarily closed\" in soup.find('div', class_ = 'skqShb').text)\n",
    "        else:\n",
    "            case_closed = str(\"Permanently closed\" in soup.find('div', class_ = 'skqShb').text)\n",
    "        #print(i, bar_no_add_remaining[\"name\"].iloc[i], case_closed)\n",
    "    except Exception:\n",
    "        case_closed = np.nan\n",
    "        #print(i, bar_no_add_remaining[\"name\"].iloc[i], \"Closed no\")\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        case_price = soup.find('span', class_ = 'mgr77e').text[1:]\n",
    "        #print(i, bar_no_add_remaining[\"name\"].iloc[i], case_price)\n",
    "    except Exception:\n",
    "        case_price = np.nan\n",
    "        #print(i, bar_no_add_remaining[\"name\"].iloc[i], \"Euro no\")\n",
    "        pass\n",
    "   \n",
    "        \n",
    "\n",
    "    poi_url = driver.current_url\n",
    "    try:\n",
    "        lat = poi_url.split(\"@\")[1].split(\",\")[0]\n",
    "        long = poi_url.split(\"@\")[1].split(\",\")[1]\n",
    "    except Exception:\n",
    "        lat = np.nan\n",
    "        long = np.nan\n",
    "        pass\n",
    "    #print(poi_url)\n",
    "    row = {\"id\": bar_id, \"name\": bar_name, \"rating\": case_rating, \"reviews\": case_reviews, \"price\": case_price, \"closed\": case_closed, \"url\": poi_url, \"lat\": lat, \"long\": long}\n",
    "    #print(row)\n",
    "    bar_reviews_no_add = pd.concat([bar_reviews_no_add, pd.DataFrame(row, index=[i])], ignore_index=True)\n",
    "\n",
    "    driver.close()\n",
    "    return bar_reviews_no_add\n",
    "\n",
    "# Insert number of iterations in range\n",
    "threadlist = []\n",
    "with ThreadPoolExecutor(max_workers=4) as executor:\n",
    "    for i in range(5):\n",
    "        threadlist.append(executor.submit(get_rating, i))\n",
    "        time.sleep(1)\n",
    "\n",
    "wait(threadlist)\n",
    "\n",
    "bar_reviews_no_add = bar_reviews_no_add.drop_duplicates(subset=\"id\", keep=False)\n",
    "bar_reviews_no_add.to_csv('data/london/bar_reviews_no_add.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>rating</th>\n",
       "      <th>reviews</th>\n",
       "      <th>price</th>\n",
       "      <th>closed</th>\n",
       "      <th>url</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1589</th>\n",
       "      <td>929290848</td>\n",
       "      <td>Heritage Kitchen &amp; Bar</td>\n",
       "      <td>4.6</td>\n",
       "      <td>343</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>https://www.google.com/maps/place/Heritage+Kit...</td>\n",
       "      <td>51.469364</td>\n",
       "      <td>-0.400025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1590</th>\n",
       "      <td>2652399072</td>\n",
       "      <td>The Fox &amp; Firkin</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1,149</td>\n",
       "      <td>€€</td>\n",
       "      <td>False</td>\n",
       "      <td>https://www.google.com/maps/place/Fox+%26+Firk...</td>\n",
       "      <td>51.456891</td>\n",
       "      <td>-0.016852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1591</th>\n",
       "      <td>2632761624</td>\n",
       "      <td>Coach &amp; Horses</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>https://www.google.com/maps/place/Daniela+K%C3...</td>\n",
       "      <td>49.968514</td>\n",
       "      <td>-2.050646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1592</th>\n",
       "      <td>279526311</td>\n",
       "      <td>The Windmill</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1,688</td>\n",
       "      <td>€€</td>\n",
       "      <td>False</td>\n",
       "      <td>https://www.google.com/maps/place/Windmill/@51...</td>\n",
       "      <td>51.512381</td>\n",
       "      <td>-9.370714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1593</th>\n",
       "      <td>9014316323</td>\n",
       "      <td>Beerblefish - Brewery and Taproom</td>\n",
       "      <td>4.7</td>\n",
       "      <td>74</td>\n",
       "      <td>€€</td>\n",
       "      <td>False</td>\n",
       "      <td>https://www.google.com/maps/place/The+Beerblef...</td>\n",
       "      <td>51.593327</td>\n",
       "      <td>-0.044431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1594</th>\n",
       "      <td>276146932</td>\n",
       "      <td>Crown &amp; Sceptre</td>\n",
       "      <td>4.2</td>\n",
       "      <td>894</td>\n",
       "      <td>€€</td>\n",
       "      <td>False</td>\n",
       "      <td>https://www.google.com/maps/place/The+Crown+%2...</td>\n",
       "      <td>51.762745</td>\n",
       "      <td>-3.895129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1595</th>\n",
       "      <td>982884990</td>\n",
       "      <td>The Adam &amp; Eve</td>\n",
       "      <td>4.5</td>\n",
       "      <td>271</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>https://www.google.com/maps/place/adam+%26+eve...</td>\n",
       "      <td>53.577155</td>\n",
       "      <td>9.803691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>984433443</td>\n",
       "      <td>The Greyhound</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>https://www.google.com/maps/place/The+Greyhoun...</td>\n",
       "      <td>52.202232</td>\n",
       "      <td>-1.472639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597</th>\n",
       "      <td>993673927</td>\n",
       "      <td>Ship Inn</td>\n",
       "      <td>4.4</td>\n",
       "      <td>321</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>https://www.google.com/maps/place/The+Ship+Inn...</td>\n",
       "      <td>52.917498</td>\n",
       "      <td>-5.211004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598</th>\n",
       "      <td>993781413</td>\n",
       "      <td>Slug &amp; Lettuce</td>\n",
       "      <td>4.4</td>\n",
       "      <td>174</td>\n",
       "      <td>€€</td>\n",
       "      <td>False</td>\n",
       "      <td>https://www.google.com/maps/place/S.L.U.T.+Clu...</td>\n",
       "      <td>52.554697</td>\n",
       "      <td>-1.046957</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              id                               name  rating reviews price  \\\n",
       "1589   929290848             Heritage Kitchen & Bar     4.6     343   NaN   \n",
       "1590  2652399072                   The Fox & Firkin     4.4   1,149    €€   \n",
       "1591  2632761624                     Coach & Horses     5.0       6   NaN   \n",
       "1592   279526311                       The Windmill     4.4   1,688    €€   \n",
       "1593  9014316323  Beerblefish - Brewery and Taproom     4.7      74    €€   \n",
       "1594   276146932                    Crown & Sceptre     4.2     894    €€   \n",
       "1595   982884990                     The Adam & Eve     4.5     271   NaN   \n",
       "1596   984433443                      The Greyhound     5.0       3   NaN   \n",
       "1597   993673927                           Ship Inn     4.4     321   NaN   \n",
       "1598   993781413                     Slug & Lettuce     4.4     174    €€   \n",
       "\n",
       "     closed                                                url        lat  \\\n",
       "1589  False  https://www.google.com/maps/place/Heritage+Kit...  51.469364   \n",
       "1590  False  https://www.google.com/maps/place/Fox+%26+Firk...  51.456891   \n",
       "1591  False  https://www.google.com/maps/place/Daniela+K%C3...  49.968514   \n",
       "1592  False  https://www.google.com/maps/place/Windmill/@51...  51.512381   \n",
       "1593  False  https://www.google.com/maps/place/The+Beerblef...  51.593327   \n",
       "1594  False  https://www.google.com/maps/place/The+Crown+%2...  51.762745   \n",
       "1595  False  https://www.google.com/maps/place/adam+%26+eve...  53.577155   \n",
       "1596  False  https://www.google.com/maps/place/The+Greyhoun...  52.202232   \n",
       "1597  False  https://www.google.com/maps/place/The+Ship+Inn...  52.917498   \n",
       "1598  False  https://www.google.com/maps/place/S.L.U.T.+Clu...  52.554697   \n",
       "\n",
       "          long  \n",
       "1589 -0.400025  \n",
       "1590 -0.016852  \n",
       "1591 -2.050646  \n",
       "1592 -9.370714  \n",
       "1593 -0.044431  \n",
       "1594 -3.895129  \n",
       "1595  9.803691  \n",
       "1596 -1.472639  \n",
       "1597 -5.211004  \n",
       "1598 -1.046957  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bar_reviews_no_add.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1599, 9)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bar_reviews_no_add.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1600, 16)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bar_no_address.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate distance to OSM coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1599, 19)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "distance_bars = bar_reviews_no_add.merge(osm_short, on=\"id\", how=\"inner\")\n",
    "distance_bars.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_bars = distance_bars.dropna(subset=\"lat\")\n",
    "distance_bars = distance_bars.dropna(subset=\"latitude\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopy.distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance(row):\n",
    "    return geopy.distance.distance((row[\"latitude\"], row[\"longitude\"]), (row[\"lat\"], row[\"long\"])).km"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_bars[\"distance\"] = distance_bars.apply(lambda row: distance(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_bars.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(537, 20)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "distance_bars[distance_bars[\"distance\"] < 0.3].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Restaurant review data scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New DF for restaurants with addresses and names to fill with reviews\n",
    "restaurant_address = osm_short[(osm_short[\"amenity\"] == \"restaurant\") & (~osm_short[\"address\"].isna()) & (~osm_short[\"name\"].isna())]\n",
    "restaurant_address = restaurant_address.reset_index().drop(columns=\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment both only the first time the code is run.\n",
    "# restaurant_reviews = bar_reviews[0:0]\n",
    "# restaurant_reviews.to_csv(('data/london/restaurant_reviews.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"restaurant_address\" must be csv on computer\n",
    "# restaurants, address not nan, web scraping loop with threading\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "restaurant_reviews = pd.read_csv(\n",
    "    \"data/london/restaurant_reviews.csv\", index_col=\"Unnamed: 0\")\n",
    "restaurant_address_remaining = restaurant_address[~restaurant_address[\"id\"].isin(\n",
    "    restaurant_reviews[\"id\"].to_list())]\n",
    "\n",
    "start = restaurant_reviews.shape[0]\n",
    "\n",
    "service = Service(ChromeDriverManager().install())\n",
    "\n",
    "\n",
    "def driver_setup():\n",
    "    options = Options()\n",
    "    options.add_argument(\"--headless=new\")\n",
    "    options.add_argument('--no-sandbox')\n",
    "    options.add_argument('--disable-dev-shm-usage')\n",
    "    driver = webdriver.Chrome(service=service, options=options)\n",
    "    return driver\n",
    "\n",
    "\n",
    "def get_rating(i):\n",
    "    global restaurant_reviews\n",
    "    bar_id = restaurant_address_remaining[\"id\"].iloc[i]\n",
    "    bar_name = restaurant_address_remaining[\"name\"].iloc[i]\n",
    "    driver = driver_setup()\n",
    "    url = f'http://maps.google.com/?q={restaurant_address_remaining[\"name\"].iloc[i]}+{restaurant_address_remaining[\"address\"].iloc[i]}'\n",
    "    driver.get(url)\n",
    "    time.sleep(1)\n",
    "\n",
    "    # Press accept all on cookie question\n",
    "    try:\n",
    "        driver.find_element(\n",
    "            By.XPATH, '//*[@id=\"yDmH0d\"]/c-wiz/div/div/div/div[2]/div[1]/div[3]/div[1]/div[1]/form[2]/div/div/button/span').click()\n",
    "        time.sleep(1)\n",
    "    except NoSuchElementException:\n",
    "        pass\n",
    "\n",
    "    # Extract raiting/num of reviews, price level and if permanently closed\n",
    "    try:\n",
    "        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "        case_reviews = soup.find('div', class_='F7nice')\n",
    "        case_rating = case_reviews.text.split(\"(\")[0]\n",
    "        case_reviews = case_reviews.text.split(\"(\")[1][:-1]\n",
    "        #print(i, restaurant_address_remaining[\"name\"].iloc[i], case_rating)\n",
    "        #print(i, restaurant_address_remaining[\"name\"].iloc[i], case_reviews)\n",
    "    except Exception:\n",
    "        case_rating = np.nan\n",
    "        case_reviews = np.nan\n",
    "        #print(i, restaurant_address_remaining[\"name\"].iloc[i], \"Rating no\")\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        case_closed = str(\"Temporarily closed\" in soup.find(\n",
    "            'div', class_='skqShb').text)\n",
    "        #print(i, restaurant_address_remaining[\"name\"].iloc[i], case_closed)\n",
    "    except Exception:\n",
    "        case_closed = np.nan\n",
    "        #print(i, restaurant_address_remaining[\"name\"].iloc[i], \"Closed no\")\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        case_price = soup.find('span', class_='mgr77e').text[1:]\n",
    "        #print(i, restaurant_address_remaining[\"name\"].iloc[i], case_price)\n",
    "    except Exception:\n",
    "        case_price = np.nan\n",
    "        #print(i, restaurant_address_remaining[\"name\"].iloc[i], \"Euro no\")\n",
    "        pass\n",
    "\n",
    "    poi_url = url\n",
    "    row = {\"id\": bar_id, \"name\": bar_name, \"rating\": case_rating,\n",
    "           \"reviews\": case_reviews, \"price\": case_price, \"closed\": case_closed, \"url\": poi_url}\n",
    "    #print(row)\n",
    "    restaurant_reviews = pd.concat(\n",
    "        [restaurant_reviews, pd.DataFrame(row, index=[i])], ignore_index=True)\n",
    "\n",
    "    driver.close()\n",
    "    return restaurant_reviews\n",
    "\n",
    "\n",
    "# Insert number of iterations wanted in range\n",
    "threadlist = []\n",
    "with ThreadPoolExecutor(max_workers=4) as executor:\n",
    "    for i in range(2):\n",
    "        threadlist.append(executor.submit(get_rating, i))\n",
    "        time.sleep(1)\n",
    "\n",
    "wait(threadlist)\n",
    "\n",
    "restaurant_reviews = restaurant_reviews.drop_duplicates(\n",
    "    subset=\"id\", keep=False)\n",
    "restaurant_reviews.to_csv('data/london/restaurant_reviews.csv')\n",
    "\n",
    "pd.options.mode.chained_assignment = \"warn\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload restaurant with address ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = get_engine()\n",
    "schema = 'hh_analytics_23_1' # your course schema name, example 'hh_analytics_22_1\n",
    "table_name = 'g1_restaurant_reviews'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The g1_restaurant_reviews table was imported successfully.\n"
     ]
    }
   ],
   "source": [
    "# Write records stored in poi_gastro to SQL database\n",
    "if engine!=None:\n",
    "    try:\n",
    "        restaurant_reviews.to_sql(name=table_name, # Name of SQL table variable\n",
    "                        con=engine, # Engine or connection\n",
    "                        schema=schema, # your class schema variable\n",
    "                        if_exists='replace', # Drop the table before inserting new values \n",
    "                        index=False, # Write DataFrame index as a column\n",
    "                        chunksize=5000, # Specify the number of rows in each batch to be written at a time\n",
    "                        method='multi') # Pass multiple values in a single INSERT clause\n",
    "        print(f\"The {table_name} table was imported successfully.\")\n",
    "    # Error handling\n",
    "    except (Exception, psycopg2.DatabaseError) as error:\n",
    "        print(error)\n",
    "        engine = None\n",
    "else:\n",
    "    print('No engine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Give access to all cohort members\n",
    "group = \"student_role_hh_analytics_23_1\"\n",
    "engine = get_engine()\n",
    "SQL = f\"GRANT ALL  ON {schema}.{table_name} to {group}\"\n",
    "with engine.begin() as conn:\n",
    "    conn.execute(SQL)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Restaurant without address scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "restaurant_reviews = pd.read_csv(\n",
    "    \"data/london/restaurant_reviews.csv\", index_col=\"Unnamed: 0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "restaurant_no_address = osm_short[(osm_short[\"amenity\"] == \"restaurant\") & (osm_short[\"address\"].isna()) & (~osm_short[\"name\"].isna())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No working address\n",
    "restaurant_remaining = restaurant_reviews[(restaurant_reviews[\"closed\"].isna())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "restaurant_no_address = pd.concat([restaurant_no_address, restaurant_remaining])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "restaurant_no_address = restaurant_no_address.reset_index().drop(columns=\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment both only the first time the code is run.\n",
    "# restaurant_reviews_no_add = bar_reviews[0:0]\n",
    "# restaurant_reviews_no_add.to_csv(\"data/london/restaurant_reviews_no_add.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "Central Restaurant len ads 0\n",
      "Central Restaurant no ads\n",
      "[]\n",
      "Karma Lounge len ads 0\n",
      "Karma Lounge no ads\n",
      "2 Old Tree Daiwan Bee 3.4\n",
      "2 Old Tree Daiwan Bee 553\n",
      "2 Old Tree Daiwan Bee False\n",
      "2 Old Tree Daiwan Bee €\n",
      "https://www.google.com/maps/place/Old+Tree+Daiwan+Bee/@51.5110545,-0.1332281,19z/data=!4m6!3m5!1s0x487604d3b7ddd157:0xa7ccf5bb73d1992f!8m2!3d51.5110545!4d-0.1325844!16s%2Fg%2F1yh805m8l\n",
      "{'id': 26845558, 'name': 'Old Tree Daiwan Bee', 'rating': '3.4', 'reviews': '553', 'price': '€', 'closed': 'False', 'url': 'https://www.google.com/maps/place/Old+Tree+Daiwan+Bee/@51.5110545,-0.1332281,19z/data=!4m6!3m5!1s0x487604d3b7ddd157:0xa7ccf5bb73d1992f!8m2!3d51.5110545!4d-0.1325844!16s%2Fg%2F1yh805m8l', 'lat': '51.5110545', 'long': '-0.1332281'}\n",
      "try list hit\n",
      "0 Central Restaurant 4.7\n",
      "0 Central Restaurant 321\n",
      "0 Central Restaurant False\n",
      "0 Central Restaurant €€\n",
      "https://www.google.com/maps/place/The+House+Restaurant/@51.6020306,-0.1935029,19z/data=!4m10!1m2!2m1!1sCentral+Restaurant!3m6!1s0x487617544e00c105:0x56245d1faba6ff19!8m2!3d51.602172!4d-0.192311!15sChJDZW50cmFsIFJlc3RhdXJhbnRaFCISY2VudHJhbCByZXN0YXVyYW50kgESaXRhbGlhbl9yZXN0YXVyYW50mgEkQ2hkRFNVaE5NRzluUzBWSlEwRm5TVVJDYVhCaWN6Tm5SUkFC4AEA!16s%2Fg%2F1tsjd3zr\n",
      "{'id': 451153, 'name': 'Central Restaurant', 'rating': '4.7', 'reviews': '321', 'price': '€€', 'closed': 'False', 'url': 'https://www.google.com/maps/place/The+House+Restaurant/@51.6020306,-0.1935029,19z/data=!4m10!1m2!2m1!1sCentral+Restaurant!3m6!1s0x487617544e00c105:0x56245d1faba6ff19!8m2!3d51.602172!4d-0.192311!15sChJDZW50cmFsIFJlc3RhdXJhbnRaFCISY2VudHJhbCByZXN0YXVyYW50kgESaXRhbGlhbl9yZXN0YXVyYW50mgEkQ2hkRFNVaE5NRzluUzBWSlEwRm5TVVJDYVhCaWN6Tm5SUkFC4AEA!16s%2Fg%2F1tsjd3zr', 'lat': '51.6020306', 'long': '-0.1935029'}\n",
      "try list hit\n",
      "1 Karma Lounge 4.6\n",
      "1 Karma Lounge 126\n",
      "1 Karma Lounge False\n",
      "1 Karma Lounge Euro no\n",
      "https://www.google.com/maps/place/Karma+Lounge/@39.8525989,-63.9417241,3z/data=!4m10!1m2!2m1!1sKarma+Lounge!3m6!1s0x48766f6fd51cccff:0x8ce62abdb0ee9320!8m2!3d51.5271141!4d-0.4815046!15sCgxLYXJtYSBMb3VuZ2VaDiIMa2FybWEgbG91bmdlkgERaW5kaWFuX3Jlc3RhdXJhbnSaASNDaFpEU1VoTk1HOW5TMFZKUTBGblNVTXRhWFJtVDFsbkVBReABAA!16s%2Fg%2F11s49mrn0t\n",
      "{'id': 26603928, 'name': 'Karma Lounge', 'rating': '4.6', 'reviews': '126', 'price': nan, 'closed': 'False', 'url': 'https://www.google.com/maps/place/Karma+Lounge/@39.8525989,-63.9417241,3z/data=!4m10!1m2!2m1!1sKarma+Lounge!3m6!1s0x48766f6fd51cccff:0x8ce62abdb0ee9320!8m2!3d51.5271141!4d-0.4815046!15sCgxLYXJtYSBMb3VuZ2VaDiIMa2FybWEgbG91bmdlkgERaW5kaWFuX3Jlc3RhdXJhbnSaASNDaFpEU1VoTk1HOW5TMFZKUTBGblNVTXRhWFJtVDFsbkVBReABAA!16s%2Fg%2F11s49mrn0t', 'lat': '39.8525989', 'long': '-63.9417241'}\n",
      "3 The Ferry 4.6\n",
      "3 The Ferry 175\n",
      "3 The Ferry False\n",
      "3 The Ferry €€\n",
      "https://www.google.com/maps/place/The+Ferry/@51.3895323,-0.3260464,19z/data=!3m1!4b1!4m6!3m5!1s0x48760baad920d31b:0x60ada98fc9c3f4c7!8m2!3d51.3895323!4d-0.3254027!16s%2Fg%2F1thk86qg\n",
      "{'id': 27390454, 'name': 'The Ferry', 'rating': '4.6', 'reviews': '175', 'price': '€€', 'closed': 'False', 'url': 'https://www.google.com/maps/place/The+Ferry/@51.3895323,-0.3260464,19z/data=!3m1!4b1!4m6!3m5!1s0x48760baad920d31b:0x60ada98fc9c3f4c7!8m2!3d51.3895323!4d-0.3254027!16s%2Fg%2F1thk86qg', 'lat': '51.3895323', 'long': '-0.3260464'}\n"
     ]
    }
   ],
   "source": [
    "# Choose from list, \"bar_reviews_no_address\" must be csv on computer\n",
    "# bars, address not nan, web scraping loop with threading\n",
    "pd.options.mode.chained_assignment = \"warn\"\n",
    "\n",
    "restaurant_reviews_no_add = pd.read_csv(\"data/london/restaurant_reviews_no_add.csv\", index_col=\"Unnamed: 0\")\n",
    "restaurant_no_add_remaining = restaurant_no_address[~restaurant_no_address[\"id\"].isin(restaurant_reviews_no_add[\"id\"].to_list())]\n",
    "\n",
    "start = restaurant_reviews_no_add.shape[0]\n",
    "\n",
    "service = Service(ChromeDriverManager().install())\n",
    "\n",
    "def driver_setup():\n",
    "    options = Options()\n",
    "    #options.add_argument(\"--headless=new\")\n",
    "    options.add_argument('--no-sandbox')\n",
    "    options.add_argument('--disable-dev-shm-usage')\n",
    "    options.add_argument('--loadExtension=\"adBlock')\n",
    "    driver = webdriver.Chrome(service=service, options=options)\n",
    "    return driver\n",
    "\n",
    "def get_rating(i):\n",
    "    global restaurant_reviews_no_add\n",
    "    restaurant_id = restaurant_no_add_remaining[\"id\"].iloc[i]\n",
    "    restaurant_name = restaurant_no_add_remaining[\"name\"].iloc[i]\n",
    "    driver=driver_setup()\n",
    "    url = f'http://maps.google.com/?ll={restaurant_no_add_remaining[\"latitude\"].iloc[i]},{restaurant_no_add_remaining[\"longitude\"].iloc[i]}'\n",
    "    driver.get(url)\n",
    "    time.sleep(1)\n",
    "\n",
    "\n",
    "    # Press accept all on cookie question\n",
    "    try:\n",
    "        driver.find_element(By.XPATH,'//*[@id=\"yDmH0d\"]/c-wiz/div/div/div/div[2]/div[1]/div[3]/div[1]/div[1]/form[2]/div/div/button/span').click()\n",
    "        time.sleep(1)\n",
    "    except NoSuchElementException:\n",
    "        pass\n",
    "\n",
    "    driver.get(url)\n",
    "\n",
    "    driver.find_element(By.XPATH,'/html/body/div[3]/div[9]/div[3]/div[1]/div[1]/div[1]/div[2]/form/div[2]/div[3]/div/input[1]').send_keys(restaurant_no_add_remaining[\"name\"].iloc[i])\n",
    "    driver.find_element(By.XPATH,'/html/body/div[3]/div[9]/div[3]/div[1]/div[1]/div[1]/div[2]/form/div[2]/div[3]/div/input[1]').send_keys(Keys.RETURN)\n",
    "    time.sleep(4)\n",
    "\n",
    "\n",
    "\n",
    "    # Extract raiting/num of reviews, price level and if permanently closed\n",
    "    try:\n",
    "        # Case for immediate result without list appearing\n",
    "        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "        case_reviews = soup.find('div', class_ = 'F7nice')\n",
    "        case_rating = case_reviews.text.split(\"(\")[0]\n",
    "        case_reviews = case_reviews.text.split(\"(\")[1][:-1]\n",
    "        print(i, restaurant_no_add_remaining[\"name\"].iloc[i], case_rating)\n",
    "        print(i, restaurant_no_add_remaining[\"name\"].iloc[i], case_reviews)\n",
    "    except Exception:\n",
    "        try:\n",
    "            try:\n",
    "                # Count the number of ads and skip them\n",
    "                ads = soup.find_all('span', {'class': 'jHLihd'})\n",
    "                print(ads)\n",
    "                print(restaurant_no_add_remaining[\"name\"].iloc[i], \"len ads\", len(ads))\n",
    "                print(restaurant_no_add_remaining[\"name\"].iloc[i], \"ads 1\", ads[0])\n",
    "                if len(ads) > 0:\n",
    "                    try:\n",
    "                        print(restaurant_no_add_remaining[\"name\"].iloc[i], \"len ads over 0\")\n",
    "                        click_list = driver.find_elements(By.CLASS_NAME, 'hfpxzc')\n",
    "                        print(restaurant_no_add_remaining[\"name\"].iloc[i], click_list[len(ads)])\n",
    "                        click_list[len(ads)].click()\n",
    "                        time.sleep(2)\n",
    "                        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "                        case_reviews = soup.find('div', class_ = 'F7nice')\n",
    "                        case_rating = case_reviews.text.split(\"(\")[0]\n",
    "                        case_reviews = case_reviews.text.split(\"(\")[1][:-1]\n",
    "                    except Exception:\n",
    "                        pass\n",
    "            except Exception:\n",
    "                # Case if no ads\n",
    "                print(restaurant_no_add_remaining[\"name\"].iloc[i], \"no ads\")\n",
    "                driver.find_element(By.CLASS_NAME, 'hfpxzc').click()\n",
    "                time.sleep(2)\n",
    "                soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "                case_reviews = soup.find('div', class_ = 'F7nice')\n",
    "                case_rating = case_reviews.text.split(\"(\")[0]\n",
    "                case_reviews = case_reviews.text.split(\"(\")[1][:-1]\n",
    "                print(\"try list hit\")\n",
    "                print(i, restaurant_no_add_remaining[\"name\"].iloc[i], case_rating)\n",
    "                print(i, restaurant_no_add_remaining[\"name\"].iloc[i], case_reviews)\n",
    "        except Exception:\n",
    "            try:\n",
    "                # If neither direct hit nor list, try again (moves to exception and sets nan)\n",
    "                soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "                case_reviews = soup.find('div', class_ = 'F7nice')\n",
    "                case_rating = case_reviews.text.split(\"(\")[0]\n",
    "                case_reviews = case_reviews.text.split(\"(\")[1][:-1]\n",
    "                print(\"try no hit\")\n",
    "                print(i, restaurant_no_add_remaining[\"name\"].iloc[i], case_rating)\n",
    "                print(i, restaurant_no_add_remaining[\"name\"].iloc[i], case_reviews)\n",
    "            except Exception:\n",
    "                case_rating = np.nan\n",
    "                case_reviews = np.nan\n",
    "                print(\"try no hit no rev/rating\")\n",
    "                print(i, restaurant_no_add_remaining[\"name\"].iloc[i], case_rating)\n",
    "                print(i, restaurant_no_add_remaining[\"name\"].iloc[i], case_reviews)\n",
    "    try:\n",
    "        if str(\"Temporarily closed\" in soup.find('div', class_ = 'skqShb').text):\n",
    "            case_closed = str(\"Temporarily closed\" in soup.find('div', class_ = 'skqShb').text)\n",
    "        else:\n",
    "            case_closed = str(\"Permanently closed\" in soup.find('div', class_ = 'skqShb').text)\n",
    "        print(i, restaurant_no_add_remaining[\"name\"].iloc[i], case_closed)\n",
    "    except Exception:\n",
    "        case_closed = np.nan\n",
    "        print(i, restaurant_no_add_remaining[\"name\"].iloc[i], \"Closed no\")\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        case_price = soup.find('span', class_ = 'mgr77e').text[1:]\n",
    "        print(i, restaurant_no_add_remaining[\"name\"].iloc[i], case_price)\n",
    "    except Exception:\n",
    "        case_price = np.nan\n",
    "        print(i, restaurant_no_add_remaining[\"name\"].iloc[i], \"Euro no\")\n",
    "        pass\n",
    "   \n",
    "        \n",
    "\n",
    "    poi_url = driver.current_url\n",
    "    try:\n",
    "        lat = poi_url.split(\"@\")[1].split(\",\")[0]\n",
    "        long = poi_url.split(\"@\")[1].split(\",\")[1]\n",
    "    except Exception:\n",
    "        lat = np.nan\n",
    "        long = np.nan\n",
    "    print(poi_url)\n",
    "    row = {\"id\": restaurant_id, \"name\": restaurant_name, \"rating\": case_rating, \"reviews\": case_reviews, \"price\": case_price, \"closed\": case_closed, \"url\": poi_url, \"lat\": lat, \"long\": long}\n",
    "    print(row)\n",
    "    restaurant_reviews_no_add = pd.concat([restaurant_reviews_no_add, pd.DataFrame(row, index=[i])], ignore_index=True)\n",
    "\n",
    "    #driver.close()\n",
    "    return restaurant_reviews_no_add\n",
    "\n",
    "# Insert number of iterations in range\n",
    "threadlist = []\n",
    "with ThreadPoolExecutor(max_workers=4) as executor:\n",
    "    for i in range(4):\n",
    "        threadlist.append(executor.submit(get_rating, i))\n",
    "        time.sleep(1)\n",
    "\n",
    "wait(threadlist)\n",
    "\n",
    "restaurant_reviews_no_add = restaurant_reviews_no_add.drop_duplicates(subset=\"id\", keep=False)\n",
    "restaurant_reviews_no_add.to_csv('data/london/restaurant_reviews_no_add.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cafe reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New DF for cafes with addresses and names to fill with reviews\n",
    "cafe_address = osm_short[(osm_short[\"amenity\"] == \"cafe\") & (~osm_short[\"address\"].isna()) & (~osm_short[\"name\"].isna())]\n",
    "cafe_address = cafe_address.reset_index().drop(columns=\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment both only the first time the code is run\n",
    "# cafe_reviews = bar_reviews[0:0]\n",
    "# cafe_reviews.to_csv(('data/london/cafe_reviews.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"cafe_address\" must be csv on computer\n",
    "# restaurants, address not nan, web scraping loop with threading\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "cafe_reviews = pd.read_csv(\n",
    "    \"data/london/cafe_reviews.csv\", index_col=\"Unnamed: 0\")\n",
    "cafe_address_remaining = cafe_address[~cafe_address[\"id\"].isin(\n",
    "    cafe_reviews[\"id\"].to_list())]\n",
    "\n",
    "start = cafe_reviews.shape[0]\n",
    "\n",
    "service = Service(ChromeDriverManager().install())\n",
    "\n",
    "\n",
    "def driver_setup():\n",
    "    options = Options()\n",
    "    options.add_argument(\"--headless=new\")\n",
    "    options.add_argument('--no-sandbox')\n",
    "    options.add_argument('--disable-dev-shm-usage')\n",
    "    driver = webdriver.Chrome(service=service, options=options)\n",
    "    return driver\n",
    "\n",
    "\n",
    "def get_rating(i):\n",
    "    global cafe_reviews\n",
    "    cafe_id = cafe_address_remaining[\"id\"].iloc[i]\n",
    "    cafe_name = cafe_address_remaining[\"name\"].iloc[i]\n",
    "    driver = driver_setup()\n",
    "    url = f'http://maps.google.com/?q={cafe_address_remaining[\"name\"].iloc[i]}+{cafe_address_remaining[\"address\"].iloc[i]}'\n",
    "    driver.get(url)\n",
    "    time.sleep(1)\n",
    "\n",
    "    # Press accept all on cookie question\n",
    "    try:\n",
    "        driver.find_element(\n",
    "            By.XPATH, '//*[@id=\"yDmH0d\"]/c-wiz/div/div/div/div[2]/div[1]/div[3]/div[1]/div[1]/form[2]/div/div/button/span').click()\n",
    "        time.sleep(1)\n",
    "    except NoSuchElementException:\n",
    "        pass\n",
    "\n",
    "    # Extract raiting/num of reviews, price level and if permanently closed\n",
    "    try:\n",
    "        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "        case_reviews = soup.find('div', class_='F7nice')\n",
    "        case_rating = case_reviews.text.split(\"(\")[0]\n",
    "        case_reviews = case_reviews.text.split(\"(\")[1][:-1]\n",
    "        #print(i, cafe_address_remaining[\"name\"].iloc[i], case_rating)\n",
    "        #print(i, cafe_address_remaining[\"name\"].iloc[i], case_reviews)\n",
    "    except Exception:\n",
    "        case_rating = np.nan\n",
    "        case_reviews = np.nan\n",
    "        #print(i, cafe_address_remaining[\"name\"].iloc[i], \"Rating no\")\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        case_closed = str(\"Temporarily closed\" in soup.find(\n",
    "            'div', class_='skqShb').text)\n",
    "        #print(i, cafe_address_remaining[\"name\"].iloc[i], case_closed)\n",
    "    except Exception:\n",
    "        case_closed = np.nan\n",
    "        #print(i, cafe_address_remaining[\"name\"].iloc[i], \"Closed no\")\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        case_price = soup.find('span', class_='mgr77e').text[1:]\n",
    "        #print(i, cafe_address_remaining[\"name\"].iloc[i], case_price)\n",
    "    except Exception:\n",
    "        case_price = np.nan\n",
    "        #print(i, cafe_address_remaining[\"name\"].iloc[i], \"Euro no\")\n",
    "        pass\n",
    "\n",
    "    poi_url = url\n",
    "    row = {\"id\": cafe_id, \"name\": cafe_name, \"rating\": case_rating,\n",
    "           \"reviews\": case_reviews, \"price\": case_price, \"closed\": case_closed, \"url\": poi_url}\n",
    "    #print(row)\n",
    "    cafe_reviews = pd.concat(\n",
    "        [cafe_reviews, pd.DataFrame(row, index=[i])], ignore_index=True)\n",
    "\n",
    "    driver.close()\n",
    "    return cafe_reviews\n",
    "\n",
    "\n",
    "# Insert number of iterations wanted in range\n",
    "threadlist = []\n",
    "with ThreadPoolExecutor(max_workers=4) as executor:\n",
    "    for i in range(50):\n",
    "        threadlist.append(executor.submit(get_rating, i))\n",
    "        time.sleep(1)\n",
    "\n",
    "wait(threadlist)\n",
    "\n",
    "cafe_reviews = cafe_reviews.drop_duplicates(\n",
    "    subset=\"id\", keep=False)\n",
    "cafe_reviews.to_csv('data/london/cafe_reviews.csv')\n",
    "\n",
    "pd.options.mode.chained_assignment = \"warn\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fast_food reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New DF for cafes with addresses and names to fill with reviews\n",
    "fast_food_address = osm_short[(osm_short[\"amenity\"] == \"fast_food\") & (~osm_short[\"address\"].isna()) & (~osm_short[\"name\"].isna())]\n",
    "fast_food_address = fast_food_address.reset_index().drop(columns=\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment both only the first time the code is run.\n",
    "# fast_food_reviews = bar_reviews[0:0]\n",
    "# fast_food_reviews.to_csv(('data/london/fast_food_reviews.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"fast_food_address\" must be csv on computer\n",
    "# restaurants, address not nan, web scraping loop with threading\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "fast_food_reviews = pd.read_csv(\n",
    "    \"data/london/fast_food_reviews.csv\", index_col=\"Unnamed: 0\")\n",
    "fast_food_address_remaining = fast_food_address[~fast_food_address[\"id\"].isin(\n",
    "    fast_food_reviews[\"id\"].to_list())]\n",
    "\n",
    "start = fast_food_reviews.shape[0]\n",
    "\n",
    "service = Service(ChromeDriverManager().install())\n",
    "\n",
    "\n",
    "def driver_setup():\n",
    "    options = Options()\n",
    "    options.add_argument(\"--headless=new\")\n",
    "    options.add_argument('--no-sandbox')\n",
    "    options.add_argument('--disable-dev-shm-usage')\n",
    "    driver = webdriver.Chrome(service=service, options=options)\n",
    "    return driver\n",
    "\n",
    "\n",
    "def get_rating(i):\n",
    "    global fast_food_reviews\n",
    "    fast_food_id = fast_food_address_remaining[\"id\"].iloc[i]\n",
    "    fast_food_name = fast_food_address_remaining[\"name\"].iloc[i]\n",
    "    driver = driver_setup()\n",
    "    url = f'http://maps.google.com/?q={fast_food_address_remaining[\"name\"].iloc[i]}+{fast_food_address_remaining[\"address\"].iloc[i]}'\n",
    "    driver.get(url)\n",
    "    time.sleep(1)\n",
    "\n",
    "    # Press accept all on cookie question\n",
    "    try:\n",
    "        driver.find_element(\n",
    "            By.XPATH, '//*[@id=\"yDmH0d\"]/c-wiz/div/div/div/div[2]/div[1]/div[3]/div[1]/div[1]/form[2]/div/div/button/span').click()\n",
    "        time.sleep(1)\n",
    "    except NoSuchElementException:\n",
    "        pass\n",
    "\n",
    "    # Extract raiting/num of reviews, price level and if permanently closed\n",
    "    try:\n",
    "        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "        case_reviews = soup.find('div', class_='F7nice')\n",
    "        case_rating = case_reviews.text.split(\"(\")[0]\n",
    "        case_reviews = case_reviews.text.split(\"(\")[1][:-1]\n",
    "        #print(i, fast_food_address_remaining[\"name\"].iloc[i], case_rating)\n",
    "        #print(i, fast_food_address_remaining[\"name\"].iloc[i], case_reviews)\n",
    "    except Exception:\n",
    "        case_rating = np.nan\n",
    "        case_reviews = np.nan\n",
    "        #print(i, fast_food_address_remaining[\"name\"].iloc[i], \"Rating no\")\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        case_closed = str(\"Temporarily closed\" in soup.find(\n",
    "            'div', class_='skqShb').text)\n",
    "        #print(i, fast_food_address_remaining[\"name\"].iloc[i], case_closed)\n",
    "    except Exception:\n",
    "        case_closed = np.nan\n",
    "        #print(i, fast_food_address_remaining[\"name\"].iloc[i], \"Closed no\")\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        case_price = soup.find('span', class_='mgr77e').text[1:]\n",
    "        #print(i, fast_food_address_remaining[\"name\"].iloc[i], case_price)\n",
    "    except Exception:\n",
    "        case_price = np.nan\n",
    "        #print(i, fast_food_address_remaining[\"name\"].iloc[i], \"Euro no\")\n",
    "        pass\n",
    "\n",
    "    poi_url = url\n",
    "    row = {\"id\": fast_food_id, \"name\": fast_food_name, \"rating\": case_rating,\n",
    "           \"reviews\": case_reviews, \"price\": case_price, \"closed\": case_closed, \"url\": poi_url}\n",
    "    #print(row)\n",
    "    fast_food_reviews = pd.concat(\n",
    "        [fast_food_reviews, pd.DataFrame(row, index=[i])], ignore_index=True)\n",
    "\n",
    "    driver.close()\n",
    "    return fast_food_reviews\n",
    "\n",
    "\n",
    "# Insert number of iterations wanted in range\n",
    "threadlist = []\n",
    "with ThreadPoolExecutor(max_workers=4) as executor:\n",
    "    for i in range(10):\n",
    "        threadlist.append(executor.submit(get_rating, i))\n",
    "        time.sleep(1)\n",
    "\n",
    "wait(threadlist)\n",
    "\n",
    "fast_food_reviews = fast_food_reviews.drop_duplicates(\n",
    "    subset=\"id\", keep=False)\n",
    "fast_food_reviews.to_csv('data/london/fast_food_reviews.csv')\n",
    "\n",
    "pd.options.mode.chained_assignment = \"warn\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nf_base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ab3d85a18739f6fff6a9c8c504adc2ff9340867b576dede986e2ee74c099e4e5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
